{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e88c501c",
   "metadata": {},
   "source": [
    "# Modeling pipeline using concatenation of multiple Time-Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c302d5",
   "metadata": {},
   "source": [
    "In this notebook, we create a modeling pipeline using the concatenation of several Time-Series generated by the simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0055ea64",
   "metadata": {},
   "source": [
    "## Modules import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0578bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import yaml\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from uvsw_part import simulation\n",
    "import copy\n",
    "from math import e\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a253c683",
   "metadata": {},
   "source": [
    "## Loading the PATH to the Lists file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9022f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_PATH_1 = \"../data/params/List1.txt\"\n",
    "LIST_PATH_2 = \"../data/params/List2.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8104c1",
   "metadata": {},
   "source": [
    "## Generation of a Time-Series with the simulator with a set of parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73e534b",
   "metadata": {},
   "source": [
    "Here, we define the function allowing to launch the simulator with the chosen parameters and to compare the result with the reference model.\n",
    "Visualizations are made with Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab73d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation(h,tension,u,clo,eps,LIST_PATH,TS_INDEX):\n",
    "    \"\"\"\n",
    "    Pipeline from input parameters to prediction models\n",
    "    \n",
    "    ParamÃ¨tres\n",
    "    ----------\n",
    "    h_          : float  : Simulator parameter\n",
    "    tension      : float : Simulator parameter\n",
    "    u            : float : Simulator parameter\n",
    "    clo          : float : Simulator parameterr\n",
    "    LIST_PATH   : string : Path to list file\n",
    "    TS_INDEX     : int   : Number of the time-series to be executed (starts at 0) \n",
    "    \n",
    "    Sortie :\n",
    "    ref : Time-Series of the reference model\n",
    "    sim : Time-Series of the simulation\n",
    "    \"\"\"\n",
    "    #Loading the List * .txt file with the path \n",
    "    data_list = pd.read_csv(LIST_PATH , delim_whitespace=True)\n",
    "    #Loading of the basic parameters of a Time-Series for the simulation with its index (Index starts at 0) \n",
    "    set_params = data_list.iloc[TS_INDEX,:]\n",
    "    \n",
    "    #Loading of the reference Time-Series according to the List file used\n",
    "    \n",
    "    list_number = LIST_PATH[-9:]# String manipulation to keep only the last portion of the path\n",
    "    \n",
    "    #Retrieve the List file number used and load the desired csv file accordingly\n",
    "    \n",
    "    if(list_number == \"List1.txt\"):\n",
    "        ref = pd.read_csv(\"../data/ref/list1/graph{}.csv\".format(set_params[\"nc\"]))\n",
    "        print(\"Liste_1\")\n",
    "        \n",
    "    if(list_number == \"List2.txt\"):\n",
    "        ref = pd.read_csv(\"../data/ref/list2/graph{}.csv\".format(set_params[\"nc\"]))\n",
    "        print(\"Liste_2\")\n",
    "        \n",
    "    if(list_number !=  \"List1.txt\" and list_number != \"List2.txt\" ):\n",
    "        print(\"error\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #print(\"################ eps value: {} ################\".format(eps_value))\n",
    "    cfg = yaml.safe_load(open('../data/config/example.in.yaml', 'r'))\n",
    "\n",
    "    #Loading the parameters to test \n",
    "\n",
    "    cfg[\"cable\"][\"h\"] = float(h)\n",
    "\n",
    "    cfg[\"simulation\"][\"tf\"] = float(set_params[\"tf[s]\"])\n",
    "\n",
    "    cfg[\"cable\"][\"tension\"] = float(tension)\n",
    "\n",
    "    cfg[\"wakeosc\"][\"u\"] = float(u)\n",
    "\n",
    "    cfg[\"wakeosc\"][\"cl0\"] = float(clo)\n",
    "\n",
    "    cfg[\"wakeosc\"][\"eps\"] = float(eps)\n",
    "\n",
    "    #Setup of the parameters allowing to produce a simulation of with the same number of points as the reference model\n",
    "\n",
    "\n",
    "    cfg[\"simulation\"][\"dt\"] = cfg[\"simulation\"][\"tf\"] / len(ref) # MODIF DT\n",
    "    cfg[\"simulation\"][\"dr\"] = cfg[\"simulation\"][\"tf\"] / len(ref) # MODIF DR\n",
    "\n",
    "\n",
    "\n",
    "    print(\"h value: \", cfg[\"cable\"][\"h\"], \" u value: \", cfg[\"wakeosc\"][\"u\"],\" tension value: \",cfg[\"cable\"][\"tension\"],\n",
    "         \"clo value \",cfg[\"wakeosc\"][\"cl0\"])\n",
    "    print(\"tf value \", cfg[\"simulation\"][\"tf\"])\n",
    "    dfy, _ = simulation.run_cable_wakeosc(cfg)\n",
    "\n",
    "\n",
    "\n",
    "    plt.figure(figsize = (20,5))\n",
    "    plt.plot(ref['time'], ref['y/d'], label = \"Reference model signal\")\n",
    "    plt.plot(dfy.index, dfy['s=0.250']/0.025, label = \"Simulation signal\")\n",
    "    plt.xlabel('time (s)')\n",
    "    plt.ylabel('Signal')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show() \n",
    "\n",
    "\n",
    "    print(\"R2 : \",r2_score(ref['y/d'],(dfy['s=0.250']/0.025).values[:-1]))\n",
    "    print(\"MSE : \",mean_squared_error(ref['y/d'],(dfy['s=0.250']/0.025).values[:-1])) # Correct\n",
    "\n",
    "    return ref,dfy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0e158f",
   "metadata": {},
   "source": [
    "## Calculation of the simulations to be concatenated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dca0182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ref_TS_1_List_2,sim_TS_1_List_2 = generation(100,32100,2.15,0.6,0.3,LIST_PATH_2,0)\n",
    "ref_TS_2_List_2,sim_TS_2_List_2 = generation(100,32200,2.15,3.0,0.3,LIST_PATH_2,1)\n",
    "ref_TS_1_List_1,sim_TS_1_List_1 = generation(309.49288554663354,11605.8732786244,0.9535838147886668,0.6,0.3,\n",
    "                                             LIST_PATH_1,5)\n",
    "ref_TS_6_List_1,sim_TS_6_List_1 = generation(385.75324043420676,20922.45861417,0.9198665553364257,0.01,0.3,\n",
    "                                             LIST_PATH_1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff7ee97",
   "metadata": {},
   "source": [
    "## Loading of all simulations and references for modeling with concatenation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee6c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_reference = []\n",
    "list_reference.append(ref_TS_1_List_2)\n",
    "list_reference.append(ref_TS_2_List_2)\n",
    "list_reference.append(ref_TS_1_List_1)\n",
    "list_reference.append(ref_TS_6_List_1)\n",
    "\n",
    "\n",
    "list_simulation = []\n",
    "list_simulation.append(sim_TS_1_List_2)\n",
    "list_simulation.append(sim_TS_2_List_2)\n",
    "list_simulation.append(sim_TS_1_List_1)\n",
    "list_simulation.append(sim_TS_6_List_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50f7342",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cf5d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(list_dfy,list_ref):\n",
    "    \"\"\"\n",
    "    Recovery of positive values from simulation models and reference models\n",
    "     Concatenation of simulations on one side and references on the other\n",
    "     Split 80/20 data \n",
    "    \n",
    "    Arguments : list_dfy : List of all simulations to concatenate\n",
    "                list_ref : List of all references to concatenate\n",
    "                \n",
    "    Sortie : X_train (80 % sim)\n",
    "            X_test (20% sim)\n",
    "            y_train (80% ref)\n",
    "            y_test (20% ref)\n",
    "               \n",
    "    \"\"\"\n",
    "    list_sim_pos = []\n",
    "    list_ref_pos = []\n",
    "    for i in range(0, len(list_dfy)): # For each simulation\n",
    "        sim_data = list_dfy[i]['s=0.250'].iloc[1:,]/0.025\n",
    "        ref_data = list_ref[i].set_index(\"time\").sort_index()['y/d']\n",
    "        \n",
    "        # Put simulation and reference in a DataFrame\n",
    "        sim_ref_data = pd.concat([\n",
    "        pd.DataFrame(sim_data.values,columns = [\"sim\"]), # Simulation values\n",
    "        pd.DataFrame(ref_data.values[ref_data.values >= 0], columns = [\"ref_pos\"]), # Reference values above 0\n",
    "        pd.DataFrame(ref_data.values[ref_data.values < 0], columns = [\"ref_neg\"])   # Reference values below 0\n",
    "        ],axis = 1)\n",
    "\n",
    "\n",
    "        pd.DataFrame(sim_data.values,columns = [\"sim\"])\n",
    "\n",
    "        sim_df = sim_ref_data\n",
    "        sim_pos = sim_df[sim_df.sim >= 0].sim.values # SImulation values above 0\n",
    "        ref_pos = sim_df[\"ref_pos\"].dropna().values # Delete Missing values\n",
    "\n",
    "        # Due ton deleting the missing value we ajust the longest vector to have the number of point as the smaller one\n",
    "        if(len(ref_pos) > (len(sim_pos))):\n",
    "            ref_pos = ref_pos[:sim_pos.shape[0]]\n",
    "        if(len(ref_pos) <= (len(sim_pos))):\n",
    "            sim_pos = sim_pos[:ref_pos.shape[0]]\n",
    "        list_sim_pos.append(sim_pos)\n",
    "        list_ref_pos.append(ref_pos)\n",
    "\n",
    "    #Concatenation of all simulation on one side and reference on the other\n",
    "    sim_pos_final = np.concatenate((list_sim_pos))\n",
    "    ref_pos_final = np.concatenate((list_ref_pos))\n",
    "\n",
    "    # Creation of the train et test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(sim_pos_final,ref_pos_final,test_size = 0.2, random_state = 143,shuffle = True)\n",
    "\n",
    "\n",
    "    X_train = X_train.reshape(-1, 1)\n",
    "    X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba258d5",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    \"\"\"\n",
    "    Train a RandomForest model and calculate the prediction\n",
    "    Arguments : X_train, \n",
    "                X_test, \n",
    "                y_train,\n",
    "                y_test\n",
    "                \n",
    "    Retour : y_pred (Random Forest model prediction)\n",
    "    \"\"\"\n",
    "    reg = RandomForestRegressor()\n",
    "    reg.fit(X_train,y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    \n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661a0e92",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b455e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_pred,y_test):\n",
    "    \"\"\"\n",
    "    Evaluation of the model prediction\n",
    "    \n",
    "    Arguments: y_pred\n",
    "                y_test\n",
    "                \n",
    "    Sortie : mse : mean_squared_error\n",
    "            rmse = root mean squared error\n",
    "            mea = mean absolute error\n",
    "            r2 = r2_score\n",
    "    \"\"\"\n",
    " \n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    rmse = mean_squared_error(y_test,y_pred,squared = False)\n",
    "    mea = mean_absolute_error(y_test,y_pred)\n",
    "    r2 = r2_score(y_test,y_pred)\n",
    "\n",
    "    return mse,rmse,mea,r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8c0ad9",
   "metadata": {},
   "source": [
    "## Model visualization with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61755fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plt_model(y_pred,y_test):\n",
    "    \"\"\"\n",
    "    Side-by-side reference and prediction plot with indicator results \n",
    "    \n",
    "    y_pred  :  numpy.ndarray  : PrÃ©diction du modÃ¨le sur les donnÃ©es test du simulateur\n",
    "    y_test  :  numpy.ndarray  : sortie du modÃ¨le de reference dont on doit se rapprocher\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    plt.figure(figsize = (20,8))\n",
    "    plt.plot(y_test, label = \"Reference model signal\")\n",
    "    plt.plot(y_pred, label = \"Prediction signal\")\n",
    "\n",
    "    mse,rmse,mea,r2_score = evaluate_model(y_pred,y_test)\n",
    "    mse_text = \"MSE = %s \" % mse\n",
    "    rmse_text = \"RMSE = %s \" % rmse\n",
    "    mea_text = \"MEA = %s \" % mea\n",
    "    r2_text = \"R2_SCORE = %s \" % r2_score\n",
    "  \n",
    "\n",
    "    plt.figtext(0.5, 0.00, mse_text, ha=\"center\", fontsize=18, bbox={\"facecolor\":\"orange\", \"alpha\":0.5, \"pad\":5})\n",
    "    plt.figtext(0.5, -0.05, rmse_text, ha=\"center\", fontsize=18, bbox={\"facecolor\":\"orange\", \"alpha\":0.5, \"pad\":5})\n",
    "    plt.figtext(0.5, -0.10, mea_text, ha=\"center\", fontsize=18, bbox={\"facecolor\":\"orange\", \"alpha\":0.5, \"pad\":5})\n",
    "    plt.figtext(0.5, -0.15, r2_text, ha=\"center\", fontsize=18, bbox={\"facecolor\":\"orange\", \"alpha\":0.5, \"pad\":5})\n",
    "        \n",
    "\n",
    "    #plt.figtext(0.5, -0.20, \"h = '{0}', tension = '{1}', u = '{2}', clo = '{3}', eps = '{4}'\".format(h,tension,u,clo,eps), ha=\"center\", fontsize=18, bbox={\"facecolor\":\"orange\", \"alpha\":0.5, \"pad\":5})\n",
    "\n",
    "    \n",
    "    \n",
    "    title = \" Comparaison entre le modÃ¨le de rÃ©ference et la prÃ©diction du modÃ¨le d'apprentissage Random Forest\"\n",
    "    plt.title(title,fontsize = 18)\n",
    "    plt.xlabel(\"Timesteps\")\n",
    "    plt.ylabel(\"Signal\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85bd6da",
   "metadata": {},
   "source": [
    "## Model visualization with Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97f67f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotly_model(y_pred,y_test):\n",
    "    \"\"\"\n",
    "    Side-by-side reference and prediction plot with indicator results\n",
    "    \n",
    "    y_pred  :  numpy.ndarray  : Model prediction on simulator test data\n",
    "    y_test  :  numpy.ndarray  : output of the reference model which we must approach\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y = y_test,\n",
    "                    name='Reference model signal'))\n",
    "    fig.add_trace(go.Scatter(y = y_pred,\n",
    "                    name='Prediction signal'))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\" Comparison between the reference model and the prediction of the Random Forest learning model\",\n",
    "        xaxis_title=\"Timesteps\",\n",
    "        yaxis_title=\"Signal\",\n",
    "        legend_title=\"Signaux\",       \n",
    "    )\n",
    "\n",
    "\n",
    "    fig.show()\n",
    "        #fig.write_html(\"../outputs/visualisation/modelisation_concatenee/Concat_4_TS.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09892a49",
   "metadata": {},
   "source": [
    "## Pipeline de modÃ©lisation concatÃ©nÃ©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fdac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = preprocessing(list_simulation,list_reference)\n",
    "y_pred = train(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "plt_model(y_pred,y_test)\n",
    "plotly_model(y_pred,y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
